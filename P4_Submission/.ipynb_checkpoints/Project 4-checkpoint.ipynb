{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set obj points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((6*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)   # each row and l -> r\n",
    "# print(objp)\n",
    "imgpts = []\n",
    "objpts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract image points, and ojb points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "dirt = 'F:\\Carnd codes\\CarND-Advanced-Lane-Lines-P4'\n",
    "images = glob.glob(dirt + '\\camera_cal\\*.jpg')\n",
    "\n",
    "image1 = images[0];\n",
    "image1 = cv2.imread(image1)\n",
    "image_size = (image1.shape[1], image1.shape[0])\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration\n",
    "Calibrate camera and save camera_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for image in images:\n",
    "#     img = cv2.imread(image)\n",
    "#     # change to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     ret, corners = cv2. findChessboardCorners(gray, (9,6), None)\n",
    "#     if ret == True:\n",
    "#         imgpts.append(corners)\n",
    "#         objpts.append(objp)   \n",
    "\n",
    "# get camera matrix\n",
    "# ret, mtx, dist, rvecs, tvecs = cv2. calibrateCamera(objpts, imgpts, image_size, None, None)\n",
    "\n",
    "# # Saving the camera matrix:\n",
    "\n",
    "# with open(dirt+'\\\\camera_matrix.pickle', 'wb') as f:\n",
    "#     pickle.dump([mtx, dist], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load camera_matrix: mtx and dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(dirt + '\\\\camera_matrix.pickle', 'rb') as f:\n",
    "    mtx,dist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define soble threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, x_thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    \n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # # Apply threshold Threshold x gradient\n",
    "    sx_binary = np.zeros_like(scaled_sobel)\n",
    "    sx_binary[(scaled_sobel >= x_thresh[0]) & (scaled_sobel <= x_thresh[1])] = 1\n",
    "       \n",
    "    return sx_binary\n",
    "\n",
    "def mag_threshold(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Calculate gradient magnitude\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_sobel = np.uint8(255 * sobel_mag / np.max(sobel_mag))\n",
    "    \n",
    "    # Apply threshold\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, dir_thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    sobel_dir = np.arctan2(np.absolute(sobelx), np.absolute(sobely))\n",
    "#     scaled_sobel = np.uint8(255 * sobel_mag / np.max(soblel_mag))\n",
    "    \n",
    "    # Apply threshold\n",
    "    dir_binary = np.zeros_like(sobel_dir)\n",
    "    dir_binary[(sobel_dir >= dir_thresh[0]) & (sobel_dir <= dir_thresh[1])] = 1\n",
    "    \n",
    "    return dir_binary\n",
    "\n",
    "def color_threshold(img, clr_thresh = (0,255)):\n",
    "    \n",
    "    clr_binary = np.zeros_like(img)\n",
    "    clr_binary[(img > clr_thresh[0]) & (img < clr_thresh[1])] = 1\n",
    "    return clr_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    l_x = 600\n",
    "    r_x = 680\n",
    "    u_y = 430\n",
    "    d_xl = 100\n",
    "    d_xr= 1200\n",
    "    d_y = 720\n",
    "    # Point(x,y) is using (x,y) as (column,row)\n",
    "    vertices = np.array([[(l_x, u_y), (r_x, u_y), (d_xr, d_y), (d_xl, d_y)]],dtype = np.int32)\n",
    "#     vertices = np.array([[(120,imshape[0]),(450, 320), (500, 320), (900,imshape[0])]], dtype=np.int32)\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of binary images using thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    img = np.copy(img)\n",
    "    # apply mask \n",
    "    \n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # convert to gray color \n",
    "    # if read image use cv2.imread, use BGR2GRAY, if use mpimg, use RGB2GRAY\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float)  \n",
    "    \n",
    "    ##\n",
    "    sobel_kernel = 3\n",
    "    sx_thresh = (20,80)\n",
    "    mag_thresh = (30,100)\n",
    "    dir_thresh = np.array([45,70])/180 * np.pi  # (35, 52) deg\n",
    "    clr_s_thresh = (80, 255)\n",
    "    orient='x'\n",
    "    \n",
    "    # Sobel x\n",
    "    sx_binary = abs_sobel_thresh(gray, orient, sobel_kernel, sx_thresh, )\n",
    "    # Sobel mag\n",
    "#     mag_binary= mag_threshold(gray, sobel_kernel, mag_thresh)\n",
    "#     # Sobel dir\n",
    "#     dir_binary = dir_threshold(gray, sobel_kernel, dir_thresh)\n",
    "#     # color\n",
    "    clr_binary = color_threshold(s_channel, clr_s_thresh)\n",
    "        \n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    stack_bi = np.dstack((np.zeros_like(clr_binary), sx_binary, clr_binary)).astype('uint8') *255\n",
    "    combined_bi = np.zeros_like(clr_binary)\n",
    "    combined_bi[(sx_binary ==1) | (clr_binary ==1)] = 1\n",
    "    combined_bi_mask = region_of_interest(combined_bi) \n",
    "#     combined_bi_mask = 255*np.dstack((combined_bi_mask,combined_bi_mask,combined_bi_mask)).astype('uint8')   \n",
    "#     return sx_binary, mag_binary, dir_binary, clr_binary\n",
    "    return stack_bi, combined_bi_mask\n",
    "# testImages = glob.glob(dirt + '\\\\test_images\\*.jpg')\n",
    "# N_img = 0\n",
    "# print(testImages[N_img].split('\\\\')[-1])\n",
    "# test1 = testImages[N_img]\n",
    "# test1 = cv2.imread(test1)\n",
    "# stack_bi, combined_bi = pipeline(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perspective_trans(img):\n",
    "    image_size = (img.shape[1], img.shape[0])  # (1280, 720)\n",
    "    l_x = 600\n",
    "    r_x = 680\n",
    "    u_y = 448\n",
    "    d_xl = 230\n",
    "    d_xr= 1080\n",
    "    d_y = 700\n",
    "    # Point(x,y) is using (x,y) as (column,row)\n",
    "    src = np.float32([[l_x, u_y], [r_x, u_y], [d_xr, d_y], [d_xl, d_y]])\n",
    "    dst = np.float32([[330,0], [950, 0],[950, image_size[1]],[330, image_size[1]]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    binary_warped = cv2.warpPerspective(img, M, image_size, flags=cv2.INTER_LINEAR)\n",
    "#     plt.plot(src[:,0],src[:,1],'r-')\n",
    "#     plt.imshow(combined_bi,cmap = 'gray')\n",
    "#     plt.figure()\n",
    "#     plt.imshow(binary_warped,cmap = 'gray')\n",
    "    return binary_warped, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lanelines(image):\n",
    "    \n",
    "    histogram = np.sum(image[np.int(image.shape[0]/2):,:], axis=0)\n",
    "    out_img = np.dstack((image, image, image)).astype('uint8')*255\n",
    "    \n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    xm_per_pix = 3.7/700\n",
    "    offset = (midpoint - np.mean(np.array([leftx_base, rightx_base]))) *  xm_per_pix\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "     # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    if left_lane.detected and right_lane.detected: \n",
    "        leftx, lefty, rightx, righty, ploty, left_fitx, right_fitx = skip_search_window(image)\n",
    "    else:\n",
    "        \n",
    "\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "\n",
    "    #     print('offset from the center of the lane line:', offset, 'm')\n",
    "        # Set height of windows\n",
    "        nwindows = 9\n",
    "        # Choose the number of sliding windows\n",
    "        window_height = np.int(image.shape[0]/nwindows)\n",
    "\n",
    "\n",
    "\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "\n",
    "    #     if left_lane.detected = True:\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "       \n",
    "        # plt.imshow(out_img)\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = image.shape[0] - (window+1)*window_height\n",
    "            win_y_high = image.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "        #     out_img = cv2.cvtColor(out_img, cv2.COLOR_GRAY2BGR)\n",
    "        #     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #         cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,1,0), 2) \n",
    "    #         cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,1,0), 2) \n",
    "    #         plt.imshow(out_img,cmap = 'gray')\n",
    "\n",
    "            #     # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # #     rect_left = np.array([[win_xleft_low,win_y_low], [win_xleft_high,win_y_low], [win_xleft_high,win_y_high], [win_xleft_low,win_y_high], [win_xleft_low,win_y_low]])\n",
    "        # #     rect_right = np.array([[win_xright_low,win_y_low], [win_xright_high,win_y_low], [win_xright_high,win_y_high], [win_xright_low,win_y_high], [win_xright_low,win_y_low]])\n",
    "        # #      good_Left_inds = cv.PointPolygonTest(rect_left, nonzero) \n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each: np.polyfit(x,y): # y:independent var,  find fitted x(column) in this case\n",
    "        # why fitting for f(y), rather than f(x):\n",
    "        # because the lane lines in the warped image are near vertical and may have the same x value for more than one y value.\n",
    "        left_fit = np.polyfit(lefty, leftx, 2) \n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # plot fitting curve\n",
    "        ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "#     out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [1, 0, 0]\n",
    "#     out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 1]\n",
    "#     # cv2.imshow('out_img',out_img)\n",
    "\n",
    "# #     plt.imshow(out_img)\n",
    "# #     plt.plot(left_fitx, ploty, color='yellow')\n",
    "# #     plt.plot(right_fitx, ploty, color='yellow')\n",
    "# #     plt.xlim(0, 1280)\n",
    "# #     plt.ylim(720, 0)\n",
    "# #     plt.show()\n",
    "#     # Create an image to draw on and an image to show the selection window\n",
    "#     out_img = np.dstack((image, image, image))*255\n",
    "#     window_img = np.zeros_like(out_img)\n",
    "#     # Color in left and right line pixels\n",
    "#     out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [1, 0, 0]\n",
    "#     out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 1]\n",
    "\n",
    "#     # Generate a polygon to illustrate the search window area\n",
    "#     # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "#     # vstack: Stack arrays in sequence vertically (row wise).\n",
    "#     left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))]) # left edge of left-line\n",
    "#     # right edge of left line, flip upside down is to build a 'circle with left edge when stack them. \n",
    "#     # Otherwise, the points are all from up to down\n",
    "#     left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))]) \n",
    "#     left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "#     right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "#     right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "#     right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "#     # Draw the lane onto the warped blank image\n",
    "#     cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,1, 0))\n",
    "#     cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,1, 0))\n",
    "    # overlap out_img(white shade image) and window_img(wide green shade), with: g(x) = (1 - a)img1 +b f_{1}img2 + c, a = 1, b = 0.3, c = 0\n",
    "#     result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "#     plt.imshow(result)\n",
    "#     # plt.imshow(binary_warped,cmap = 'gray')\n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='yellow')\n",
    "#     plt.xlim(0, 1280)\n",
    "#     plt.ylim(720, 0)\n",
    "    return out_img, offset, ploty,leftx, lefty, rightx, righty, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skip_search_window(image):\n",
    "    nonzero =image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_fit = left_lane.best_fit_coef\n",
    "    right_fit = right_lane.best_fit_coef\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, ploty, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_curveture(ploty, leftx, lefty, rightx, righty):\n",
    "    y_eval = np.max(ploty)\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "#     print(left_curverad, 'm', right_curverad, 'm')\n",
    "# Example values: 632.1 m    626.2 m\n",
    "\n",
    "   \n",
    "\n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check: curvature of left and right, if separated with right distance ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sanity_check(left_curverad, right_curverad, left_fitx, right_fitx):\n",
    "    wid_tor_min = 2.8 # [m] mim width of dashed line: 3\n",
    "    wid_tor_max = 4.2 # [m] max width of solid line: 3.7\n",
    "    xm_per_pix = 3.7/700\n",
    "    mid_pos = int((left_fitx.shape[0])/2)\n",
    "    bottom_dis = (right_fitx[-1] - left_fitx[-1])* xm_per_pix\n",
    "    mid_dis = (right_fitx[mid_pos] - left_fitx[mid_pos]) * xm_per_pix\n",
    "    top_dis = (right_fitx[0] - left_fitx[0]) * xm_per_pix\n",
    "    sign_curve = np.sign(left_curverad * right_curverad)\n",
    "    \n",
    "#     print(bottom_dis > wid_tor_min, bottom_dis < wid_tor_max, top_dis > wid_tor_min, top_dis < wid_tor_max, \\\n",
    "#     mid_dis > wid_tor_min,  mid_dis < wid_tor_max, sign_curve > 0)\n",
    "    if  bottom_dis > wid_tor_min and  bottom_dis < wid_tor_max \\\n",
    "    and mid_dis > wid_tor_min and  mid_dis < wid_tor_max and sign_curve > 0:\n",
    "        \n",
    "        detected = True\n",
    "    else:\n",
    "        detected = False\n",
    "        \n",
    "    return detected\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def warped_back(binary_warped,left_fitx, right_fitx, ploty, Minv, img):\n",
    "    newwartp = None\n",
    "    bi_warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((bi_warp_zero, bi_warp_zero, bi_warp_zero))*255\n",
    "#     print(np.shape(left_fitx))\n",
    "#     print(np.shape(ploty))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, image_size)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "from collections import deque # used for append n fits\n",
    "class Line(object):\n",
    "    def __init__(self, n=5):\n",
    "        \n",
    "        # number of buffer frames\n",
    "        self.buffer = n\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque([],maxlen=n) \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        \n",
    "        #polynomial coefficients for the n recent fit\n",
    "        self.recent_fit_coef = deque([],maxlen=n)    \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit_coef = [np.array([False])]\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit_coef = None  \n",
    "          \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "    def cal_fit_coef(self):\n",
    "        self.current_fit_coef = np.polyfit(self.ally, self.allx, 2)\n",
    "    def update(self, detx, dety, fitx, curverad, offset):\n",
    "        \n",
    "        self.detected = True\n",
    "#         print('update_fitx',np.shape(fitx))\n",
    "        self.allx = detx\n",
    "        self.ally = dety\n",
    "        self.recent_xfitted.appendleft(fitx)\n",
    "        \n",
    "        self.cal_fit_coef()\n",
    "        self.recent_fit_coef.appendleft(self.current_fit_coef)\n",
    "        if np.shape(self.recent_xfitted)[0] > self.buffer:\n",
    "            remove_last()\n",
    "            \n",
    "        self.bestx = np.mean(self.recent_xfitted, axis = 0)\n",
    "        self.best_fit_coef = np.mean(self.recent_fit_coef, axis = 0)\n",
    "        self.radius_of_curvature = curverad # [m]\n",
    "        self.line_base_pos = offset\n",
    "        \n",
    "    def remove_last(self):\n",
    "        self.recent_xfitted.pop()\n",
    "        self.recent_fit_coef.appendleft.pop()\n",
    "        \n",
    "#         print('after update_fitx',np.shape(self.recent_xfitted))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = deque(np.array([[0,1], [2,1]]))\n",
    "# print(d)\n",
    "# d.pop()\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    global left_lane\n",
    "    global right_lane\n",
    "    with open(dirt + '\\\\camera_matrix.pickle', 'rb') as f:\n",
    "        mtx,dist = pickle.load(f)\n",
    "    \n",
    "    test1_undist = cv2.undistort(image,mtx,dist, None, mtx)\n",
    "#     test1_undist = cv2.cvtColor(test1_undist, cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(test1_undist)\n",
    "\n",
    "    stack_bi, combined_bi = pipeline(test1_undist)\n",
    "#     plt.imshow(combined_bi)\n",
    "    binary_warped, Minv = perspective_trans(combined_bi)\n",
    "    out_img, offset, ploty,leftx, lefty, rightx, righty, left_fitx, right_fitx = find_lanelines(binary_warped)\n",
    "#     print(np.shape(left_fitx))\n",
    "#     print(np.shape(right_fitx))\n",
    "#     print(left_fitx != None)\n",
    "#     if left_fitx != None and right_fitx!= None:\n",
    "    left_curverad, right_curverad = find_curveture(ploty, leftx, lefty, rightx, righty)\n",
    "#     print(np.shape(left_fitx))\n",
    "    # To do: sanity check and update Line class\n",
    "    detected = sanity_check(left_curverad, right_curverad, left_fitx, right_fitx)\n",
    "#     print('Update?', detected)\n",
    "\n",
    "    avg_radius_meters = []\n",
    "    if detected == True: \n",
    "        left_lane.update(leftx, lefty, left_fitx, left_curverad, offset)\n",
    "        right_lane.update(rightx, righty, right_fitx, right_curverad, offset)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        left_fitx = left_lane.bestx\n",
    "        right_fitx = right_lane.bestx\n",
    "        left_curverad = left_lane.radius_of_curvature\n",
    "        right_curverad = right_lane.radius_of_curvature\n",
    "\n",
    "    result = warped_back(binary_warped,left_fitx, right_fitx, ploty, Minv, test1_undist)\n",
    "#     result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     if left_lane.radius_of_curvature = True and right_lane.radius_of_curvature = True:\n",
    "\n",
    "    avg_radius_meters = np.mean([left_curverad, right_curverad])\n",
    "\n",
    "\n",
    "#             print textradius_of_curvatured\n",
    "#             print('left curvature:', left_lane.radius_of_curvature, ' right curvature:', right_lane.radius_of_curvature)\n",
    "\n",
    "#     plt.imshow(result)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = \"Radius of Curvature of the Lane: {:.0f} m\".format(avg_radius_meters)\n",
    "    cv2.putText(result, text, (50,50), font, 1, (255,255,255), 2)\n",
    "    text = \"Vehicle Position: Offset Right from Center with {:.2f} m\".format(offset)\n",
    "    cv2.putText(result, text, (50,100), font, 1, (255,255,255), 2)\n",
    "    \n",
    "#     else:\n",
    "#         result =  test1_undist\n",
    "       \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirt_test = 'F:\\Carnd codes\\CarND-Advanced-Lane-Lines'\n",
    "testImages = glob.glob(dirt_test + '\\\\test_images\\\\harder\\*.jpg')\n",
    "# testImages = glob.glob(dirt + '\\\\test_images\\*.jpg')\n",
    "# testImages = testImages\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "# testImages = testImages\n",
    "for test1 in testImages[0:1]:\n",
    "# N_img = 0\n",
    "# test1 = testImages[N_img]\n",
    "    print('test image:',test1.split('\\\\')[-1])\n",
    "    test1 = cv2.imread(test1)\n",
    "    \n",
    "    # define Line class for left and right lane lines\n",
    "\n",
    "\n",
    "    result = process_image(test1)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(test1, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Undistorted Image')\n",
    "\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Detected Lane Line')\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_output5.mp4\n",
      "[MoviePy] Writing video ./project_video_output5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [12:55<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_output5.mp4 \n",
      "\n",
      "Wall time: 12min 59s\n"
     ]
    }
   ],
   "source": [
    "left_lane = Line(7)\n",
    "right_lane = Line(7)\n",
    "project_video_output = \"./project_video_output5.mp4\"\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(project_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./project_video_output5.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testImages = glob.glob(dirt + '\\\\test_images\\*.jpg')\n",
    "# # for test1 in testImages:\n",
    "    \n",
    "# test1 = testImages[4]\n",
    "# test1 = cv2.imread(test1)\n",
    "# #     #plt.imshow(test1)\n",
    "# test1_undist = cv2.undistort(test1,mtx,dist, None, mtx)\n",
    "# stack_bi, combined_bi = pipeline(test1_undist)\n",
    "\n",
    "# binary_warped, Minv = perspective_trans(combined_bi)\n",
    "# out_img, offset, ploty,leftx, lefty, rightx, righty, left_fitx, right_fitx = find_lanelines(binary_warped)\n",
    "# avg_radius_meters = find_curveture(ploty, leftx, lefty, rightx, righty)\n",
    "# result = warped_back(binary_warped,left_fitx, right_fitx, ploty, Minv, test1_undist)\n",
    "\n",
    "\n",
    "# print(avg_radius_meters, 'm')\n",
    "# print('offset from the center of the lane line:', offset, 'm')\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "# f.tight_layout()\n",
    "\n",
    "# ax1.imshow(cv2.cvtColor(test1_undist, cv2.COLOR_BGR2RGB))\n",
    "# ax1.set_title('Undistorted Image')\n",
    "\n",
    "# ax2.imshow(result)\n",
    "# ax2.set_title('Detected Lane Line')\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
